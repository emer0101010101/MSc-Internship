{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras est une librairie Python qui permet d'avoir accès aux fonctions proposées par plusieurs librairies de machine learning (comme TensorFlow). Elle permet de simplifier la vie des neophytes en python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Perceptron simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation ici d'un jeu de données simple: probleme de discrimination binaire dans le plan. Les frontieres prenent la forme d'une parabole  \n",
    "                   Si (0.1 * X2 > X1²)  Alors (Y = positif) Sinon (Y = négatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement du dossier + importation des données\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:\\\\Users\\\\Utilisateur\\\\Downloads\")\n",
    "D = pd.read_table(\"artificial2d_data2.txt\",sep=\"\\t\",header=0)\n",
    "\n",
    "#tutoriels-data-mining.blogspot.com/2013/04/parametrer-le-perceptron-multicouche.html -> lien pour avoir le tableau de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 3 columns):\n",
      "X1    2000 non-null float64\n",
      "X2    2000 non-null float64\n",
      "Y     2000 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(D.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    1141\n",
      "pos     859\n",
      "Name: Y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.value_counts(D.Y))   #regarde les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.zeros(D.shape[0])\n",
    "y[D.Y=='pos'] = 1  #ici positif = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))    #859 observation \"positives\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subdvision en échantillons d'apprentissage (1500 observations) et de test (500 observations)\n",
    "! il doit y avoir la même proportions d'observations positives (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1     X2\n",
      "0    -0.355  0.676\n",
      "1     0.464  0.681\n",
      "2     0.001  0.294\n",
      "3     0.427  0.592\n",
      "4    -0.391  0.823\n",
      "...     ...    ...\n",
      "1995  0.194  0.539\n",
      "1996  0.061  0.998\n",
      "1997  0.083  0.156\n",
      "1998  0.184  0.556\n",
      "1999 -0.309  0.827\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "X = D.iloc[:,:2]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42933333333333334 0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#subdivision en 500 observations pour le test\n",
    "XTrain,XTest,yTrain,yTest = model_selection.train_test_split(X,y,test_size=500,random_state=1,stratify=y)\n",
    "\n",
    "print(np.mean(yTrain),np.mean(yTest))    #on observe la même proportions d'observations positives\n",
    "                                         #on peut commencer le processus d'apprentissage supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Sequential, strucute vide qui permet de définir un empilement de couches de neurones\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential = ajoute des couches de façon sequentielle\n",
    "modelSimple = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture perception simple\n",
    "modelSimple.add(Dense(units=1,input_dim=2,activation=\"sigmoid\"))\n",
    "#on ajoute une couche qui relie directement la couche d'entrée #input_dim, nbr de neurones = nbr variables predictives\n",
    "# avec la couche de sortir #units = 1, 1 sortie ici la variable est binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Utilisateur/images/perceptron.jpg \"perceptron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithme d'apprentissage \n",
    "modelSimple.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "#adam, algorithme d'optimisation\n",
    "#accuracy, taux de succès\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 1s 355us/step - loss: 0.7130 - accuracy: 0.3240\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.7089 - accuracy: 0.3140\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.7052 - accuracy: 0.3173\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.7017 - accuracy: 0.3093\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.6985 - accuracy: 0.3087\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6956 - accuracy: 0.3053\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6927 - accuracy: 0.3233\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6902 - accuracy: 0.3373\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6876 - accuracy: 0.3533\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6853 - accuracy: 0.3780\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6831 - accuracy: 0.3980\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6810 - accuracy: 0.4227\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6791 - accuracy: 0.4413\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6772 - accuracy: 0.4640\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6755 - accuracy: 0.4793\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6739 - accuracy: 0.4900\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6723 - accuracy: 0.5067\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6708 - accuracy: 0.5160\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6694 - accuracy: 0.5220\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6681 - accuracy: 0.5280\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6667 - accuracy: 0.5400\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6655 - accuracy: 0.5573\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6643 - accuracy: 0.5713\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6632 - accuracy: 0.5753\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6621 - accuracy: 0.5767\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6612 - accuracy: 0.6033\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6601 - accuracy: 0.6073\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6592 - accuracy: 0.6093\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 0s 186us/step - loss: 0.6583 - accuracy: 0.6127\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.6574 - accuracy: 0.6207\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.6566 - accuracy: 0.6200\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6558 - accuracy: 0.6220\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.6551 - accuracy: 0.6213\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.6544 - accuracy: 0.6220\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.6537 - accuracy: 0.6260\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.6530 - accuracy: 0.6247\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.6524 - accuracy: 0.6247\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.6518 - accuracy: 0.6313\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.6512 - accuracy: 0.6287\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6506 - accuracy: 0.6287\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6501 - accuracy: 0.6267\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6496 - accuracy: 0.6360\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6491 - accuracy: 0.6320\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6486 - accuracy: 0.6313\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6482 - accuracy: 0.6320\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6477 - accuracy: 0.6300\n",
      "Epoch 47/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6473 - accuracy: 0.6313\n",
      "Epoch 48/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6470 - accuracy: 0.6313\n",
      "Epoch 49/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6464 - accuracy: 0.6320\n",
      "Epoch 50/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6461 - accuracy: 0.6367\n",
      "Epoch 51/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6458 - accuracy: 0.6307\n",
      "Epoch 52/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6454 - accuracy: 0.6307\n",
      "Epoch 53/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6451 - accuracy: 0.6373\n",
      "Epoch 54/150\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.6447 - accuracy: 0.6373\n",
      "Epoch 55/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6444 - accuracy: 0.6367\n",
      "Epoch 56/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6442 - accuracy: 0.6347\n",
      "Epoch 57/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6439 - accuracy: 0.6360\n",
      "Epoch 58/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6436 - accuracy: 0.6353\n",
      "Epoch 59/150\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6434 - accuracy: 0.6353\n",
      "Epoch 60/150\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.6431 - accuracy: 0.6353\n",
      "Epoch 61/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6430 - accuracy: 0.6347\n",
      "Epoch 62/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6427 - accuracy: 0.6347\n",
      "Epoch 63/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6424 - accuracy: 0.6353\n",
      "Epoch 64/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6423 - accuracy: 0.6367\n",
      "Epoch 65/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6420 - accuracy: 0.6367\n",
      "Epoch 66/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6419 - accuracy: 0.6373\n",
      "Epoch 67/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6417 - accuracy: 0.6367\n",
      "Epoch 68/150\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6415 - accuracy: 0.6380\n",
      "Epoch 69/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6414 - accuracy: 0.6347\n",
      "Epoch 70/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6412 - accuracy: 0.6340\n",
      "Epoch 71/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6410 - accuracy: 0.6380\n",
      "Epoch 72/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6409 - accuracy: 0.6367\n",
      "Epoch 73/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6407 - accuracy: 0.6353\n",
      "Epoch 74/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6406 - accuracy: 0.6360\n",
      "Epoch 75/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6405 - accuracy: 0.6347\n",
      "Epoch 76/150\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6404 - accuracy: 0.6387\n",
      "Epoch 77/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6402 - accuracy: 0.6367\n",
      "Epoch 78/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6401 - accuracy: 0.6387\n",
      "Epoch 79/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6400 - accuracy: 0.6367\n",
      "Epoch 80/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6399 - accuracy: 0.6353\n",
      "Epoch 81/150\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6398 - accuracy: 0.6353\n",
      "Epoch 82/150\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6397 - accuracy: 0.6373\n",
      "Epoch 83/150\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.6396 - accuracy: 0.6373\n",
      "Epoch 84/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6395 - accuracy: 0.6373\n",
      "Epoch 85/150\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6394 - accuracy: 0.6407\n",
      "Epoch 86/150\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6394 - accuracy: 0.6393\n",
      "Epoch 87/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6392 - accuracy: 0.6400\n",
      "Epoch 88/150\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.6392 - accuracy: 0.6380\n",
      "Epoch 89/150\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6392 - accuracy: 0.6353\n",
      "Epoch 90/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6390 - accuracy: 0.6380\n",
      "Epoch 91/150\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6389 - accuracy: 0.6393\n",
      "Epoch 92/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6389 - accuracy: 0.6413\n",
      "Epoch 93/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6388 - accuracy: 0.6360\n",
      "Epoch 94/150\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6388 - accuracy: 0.6387\n",
      "Epoch 95/150\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.6387 - accuracy: 0.6393\n",
      "Epoch 96/150\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6386 - accuracy: 0.6373\n",
      "Epoch 97/150\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.6386 - accuracy: 0.6367\n",
      "Epoch 98/150\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6385 - accuracy: 0.6407\n",
      "Epoch 99/150\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.6385 - accuracy: 0.6393\n",
      "Epoch 100/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6385 - accuracy: 0.6393\n",
      "Epoch 101/150\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6384 - accuracy: 0.6393\n",
      "Epoch 102/150\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6384 - accuracy: 0.6373\n",
      "Epoch 103/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6383 - accuracy: 0.6413\n",
      "Epoch 104/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6383 - accuracy: 0.6393\n",
      "Epoch 105/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6382 - accuracy: 0.6400\n",
      "Epoch 106/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6381 - accuracy: 0.6420\n",
      "Epoch 107/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.6382 - accuracy: 0.6400\n",
      "Epoch 108/150\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.6381 - accuracy: 0.6367\n",
      "Epoch 109/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.6381 - accuracy: 0.6427\n",
      "Epoch 110/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6381 - accuracy: 0.6360\n",
      "Epoch 111/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6380 - accuracy: 0.6393\n",
      "Epoch 112/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6381 - accuracy: 0.6360\n",
      "Epoch 113/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6379 - accuracy: 0.6360\n",
      "Epoch 114/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6379 - accuracy: 0.6380\n",
      "Epoch 115/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6379 - accuracy: 0.6360\n",
      "Epoch 116/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6379 - accuracy: 0.6380\n",
      "Epoch 117/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6378 - accuracy: 0.6367\n",
      "Epoch 118/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6379 - accuracy: 0.6367\n",
      "Epoch 119/150\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.6378 - accuracy: 0.6360\n",
      "Epoch 120/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6378 - accuracy: 0.6360\n",
      "Epoch 121/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6377 - accuracy: 0.6373\n",
      "Epoch 122/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6379 - accuracy: 0.6380\n",
      "Epoch 123/150\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.6377 - accuracy: 0.6373\n",
      "Epoch 124/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6377 - accuracy: 0.6427\n",
      "Epoch 125/150\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6377 - accuracy: 0.6387\n",
      "Epoch 126/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6376 - accuracy: 0.6373\n",
      "Epoch 127/150\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 128/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 129/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6376 - accuracy: 0.6367\n",
      "Epoch 130/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6377 - accuracy: 0.6373\n",
      "Epoch 131/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6376 - accuracy: 0.6387\n",
      "Epoch 132/150\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.6376 - accuracy: 0.6367\n",
      "Epoch 133/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6376 - accuracy: 0.6373\n",
      "Epoch 134/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 135/150\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.6375 - accuracy: 0.6373\n",
      "Epoch 136/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6375 - accuracy: 0.6400\n",
      "Epoch 137/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6375 - accuracy: 0.6393\n",
      "Epoch 138/150\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6375 - accuracy: 0.6367\n",
      "Epoch 139/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6376 - accuracy: 0.6400\n",
      "Epoch 140/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6375 - accuracy: 0.6387\n",
      "Epoch 141/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6374 - accuracy: 0.6373\n",
      "Epoch 142/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6374 - accuracy: 0.6380\n",
      "Epoch 143/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.6375 - accuracy: 0.6367\n",
      "Epoch 144/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6375 - accuracy: 0.6360\n",
      "Epoch 145/150\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.6374 - accuracy: 0.6380\n",
      "Epoch 146/150\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.6374 - accuracy: 0.6380\n",
      "Epoch 147/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6374 - accuracy: 0.6373\n",
      "Epoch 148/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6374 - accuracy: 0.6380\n",
      "Epoch 149/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6374 - accuracy: 0.6373\n",
      "Epoch 150/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6374 - accuracy: 0.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a427b4b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apprentissage\n",
    "modelSimple.fit(XTrain,yTrain,epochs=150,batch_size=10)\n",
    "#epochs : nbr max d'iterations\n",
    "#batch_size : nbr d'observations avec de remettre a jour poids synaptiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.15561286],\n",
      "       [2.0851707 ]], dtype=float32), array([-1.3686322], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(modelSimple.get_weights())\n",
    "#Petite matrice 2x1\n",
    "#poids de 2 neurones d'entrées + biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#echantillon test\n",
    "predic=modelSimple.predict_classes(XTest)\n",
    "print(predic[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(yTest,predic))\n",
    "\n",
    "#0.64 environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Perceptron multicouche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même jeu de données qu'en I mais ici on va construire un modèle plus complexe (input layer:3 neurones, 1 couche cachée: 3 neurones, 1 couche de sortie 1 neurone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmc = Sequential ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmc.add(Dense(units=3,input_dim=2,activation=\"sigmoid\"))\n",
    "modelmc.add(Dense(units=1,activation=\"sigmoid\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#algorithme d'apprentissage \n",
    "\n",
    "modelmc.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 1s 409us/step - loss: 0.6840 - accuracy: 0.5707\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.6768 - accuracy: 0.5707\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6741 - accuracy: 0.5707\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6727 - accuracy: 0.5707\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.6719 - accuracy: 0.5707\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6710 - accuracy: 0.5707\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6701 - accuracy: 0.5707\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.6693 - accuracy: 0.5707\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6682 - accuracy: 0.5707\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6673 - accuracy: 0.5707\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6664 - accuracy: 0.5707\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.6654 - accuracy: 0.5707\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6642 - accuracy: 0.5707\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.6632 - accuracy: 0.5707\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6620 - accuracy: 0.5707\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6610 - accuracy: 0.5707\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6599 - accuracy: 0.5593\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6588 - accuracy: 0.5613\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6577 - accuracy: 0.5567\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6566 - accuracy: 0.5547\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6555 - accuracy: 0.5547\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6544 - accuracy: 0.5567\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6533 - accuracy: 0.5613\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6522 - accuracy: 0.5667\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.6510 - accuracy: 0.5640\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6499 - accuracy: 0.5687\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.6489 - accuracy: 0.5933\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.6478 - accuracy: 0.5873\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6467 - accuracy: 0.5967\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6457 - accuracy: 0.6053\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6446 - accuracy: 0.6047\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6435 - accuracy: 0.6153\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6424 - accuracy: 0.6193\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6413 - accuracy: 0.6273\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6403 - accuracy: 0.6267\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6392 - accuracy: 0.6287\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6382 - accuracy: 0.6300\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6371 - accuracy: 0.6347\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6359 - accuracy: 0.6347\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6348 - accuracy: 0.6380\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.6337 - accuracy: 0.6453\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6324 - accuracy: 0.6420\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6312 - accuracy: 0.6487\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.6299 - accuracy: 0.6520\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6287 - accuracy: 0.6553\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6272 - accuracy: 0.6567\n",
      "Epoch 47/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6259 - accuracy: 0.6580\n",
      "Epoch 48/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6244 - accuracy: 0.6613\n",
      "Epoch 49/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6227 - accuracy: 0.6647\n",
      "Epoch 50/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6212 - accuracy: 0.6667\n",
      "Epoch 51/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.6195 - accuracy: 0.6660\n",
      "Epoch 52/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6177 - accuracy: 0.6687\n",
      "Epoch 53/150\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.6159 - accuracy: 0.6747\n",
      "Epoch 54/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.6139 - accuracy: 0.6773\n",
      "Epoch 55/150\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.6118 - accuracy: 0.6820\n",
      "Epoch 56/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6097 - accuracy: 0.6813\n",
      "Epoch 57/150\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.6074 - accuracy: 0.6867\n",
      "Epoch 58/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.6051 - accuracy: 0.6953\n",
      "Epoch 59/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6025 - accuracy: 0.6947\n",
      "Epoch 60/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.5999 - accuracy: 0.6993\n",
      "Epoch 61/150\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.5973 - accuracy: 0.7033\n",
      "Epoch 62/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5944 - accuracy: 0.7053\n",
      "Epoch 63/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.5916 - accuracy: 0.7107\n",
      "Epoch 64/150\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.5885 - accuracy: 0.7120\n",
      "Epoch 65/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.5853 - accuracy: 0.7180\n",
      "Epoch 66/150\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.5820 - accuracy: 0.7233\n",
      "Epoch 67/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.5787 - accuracy: 0.7273\n",
      "Epoch 68/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.5751 - accuracy: 0.7287\n",
      "Epoch 69/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5714 - accuracy: 0.7327\n",
      "Epoch 70/150\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.5677 - accuracy: 0.7347\n",
      "Epoch 71/150\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.5637 - accuracy: 0.7353\n",
      "Epoch 72/150\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.5598 - accuracy: 0.7407\n",
      "Epoch 73/150\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.5555 - accuracy: 0.7433\n",
      "Epoch 74/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.5512 - accuracy: 0.7440\n",
      "Epoch 75/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.5470 - accuracy: 0.7467\n",
      "Epoch 76/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.5423 - accuracy: 0.7527\n",
      "Epoch 77/150\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.5378 - accuracy: 0.7553\n",
      "Epoch 78/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.5330 - accuracy: 0.7613\n",
      "Epoch 79/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.5282 - accuracy: 0.7680\n",
      "Epoch 80/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.5231 - accuracy: 0.7713\n",
      "Epoch 81/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.5180 - accuracy: 0.7747\n",
      "Epoch 82/150\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5128 - accuracy: 0.7787\n",
      "Epoch 83/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5075 - accuracy: 0.7840\n",
      "Epoch 84/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5021 - accuracy: 0.7887\n",
      "Epoch 85/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.4967 - accuracy: 0.7913\n",
      "Epoch 86/150\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.4910 - accuracy: 0.7993\n",
      "Epoch 87/150\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.4853 - accuracy: 0.8007\n",
      "Epoch 88/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.4795 - accuracy: 0.8040\n",
      "Epoch 89/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.4735 - accuracy: 0.8080\n",
      "Epoch 90/150\n",
      "1500/1500 [==============================] - 0s 212us/step - loss: 0.4676 - accuracy: 0.8140\n",
      "Epoch 91/150\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.4616 - accuracy: 0.8180\n",
      "Epoch 92/150\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.4554 - accuracy: 0.8220\n",
      "Epoch 93/150\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.4493 - accuracy: 0.8247\n",
      "Epoch 94/150\n",
      "1500/1500 [==============================] - 0s 186us/step - loss: 0.4431 - accuracy: 0.8287\n",
      "Epoch 95/150\n",
      "1500/1500 [==============================] - 0s 204us/step - loss: 0.4367 - accuracy: 0.8353\n",
      "Epoch 96/150\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.4305 - accuracy: 0.8380\n",
      "Epoch 97/150\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.4242 - accuracy: 0.8467\n",
      "Epoch 98/150\n",
      "1500/1500 [==============================] - 0s 199us/step - loss: 0.4177 - accuracy: 0.8533\n",
      "Epoch 99/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.4115 - accuracy: 0.8593\n",
      "Epoch 100/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.4051 - accuracy: 0.8660\n",
      "Epoch 101/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3987 - accuracy: 0.8700\n",
      "Epoch 102/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3924 - accuracy: 0.8760\n",
      "Epoch 103/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3860 - accuracy: 0.8807\n",
      "Epoch 104/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.3798 - accuracy: 0.8847\n",
      "Epoch 105/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3735 - accuracy: 0.8873\n",
      "Epoch 106/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3674 - accuracy: 0.8920\n",
      "Epoch 107/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.3612 - accuracy: 0.8980\n",
      "Epoch 108/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.3552 - accuracy: 0.8980\n",
      "Epoch 109/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3492 - accuracy: 0.9040\n",
      "Epoch 110/150\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.3432 - accuracy: 0.9093\n",
      "Epoch 111/150\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.3373 - accuracy: 0.9113\n",
      "Epoch 112/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.3314 - accuracy: 0.9147\n",
      "Epoch 113/150\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.3258 - accuracy: 0.9167\n",
      "Epoch 114/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.3201 - accuracy: 0.9213\n",
      "Epoch 115/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3146 - accuracy: 0.9273\n",
      "Epoch 116/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.3091 - accuracy: 0.9293\n",
      "Epoch 117/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.3037 - accuracy: 0.9307\n",
      "Epoch 118/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2983 - accuracy: 0.9333\n",
      "Epoch 119/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2932 - accuracy: 0.9380\n",
      "Epoch 120/150\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.2881 - accuracy: 0.9400\n",
      "Epoch 121/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.2831 - accuracy: 0.9420\n",
      "Epoch 122/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2782 - accuracy: 0.9487\n",
      "Epoch 123/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.2735 - accuracy: 0.9507\n",
      "Epoch 124/150\n",
      "1500/1500 [==============================] - 0s 182us/step - loss: 0.2687 - accuracy: 0.9547\n",
      "Epoch 125/150\n",
      "1500/1500 [==============================] - 0s 205us/step - loss: 0.2641 - accuracy: 0.9567\n",
      "Epoch 126/150\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.2596 - accuracy: 0.9580\n",
      "Epoch 127/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2554 - accuracy: 0.9627\n",
      "Epoch 128/150\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.2510 - accuracy: 0.9653\n",
      "Epoch 129/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2469 - accuracy: 0.9647\n",
      "Epoch 130/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.2428 - accuracy: 0.9680\n",
      "Epoch 131/150\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2390 - accuracy: 0.9673\n",
      "Epoch 132/150\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.2351 - accuracy: 0.9733\n",
      "Epoch 133/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.2313 - accuracy: 0.9720\n",
      "Epoch 134/150\n",
      "1500/1500 [==============================] - 0s 168us/step - loss: 0.2278 - accuracy: 0.9747\n",
      "Epoch 135/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.2242 - accuracy: 0.9787\n",
      "Epoch 136/150\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2208 - accuracy: 0.9793\n",
      "Epoch 137/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.2175 - accuracy: 0.9827\n",
      "Epoch 138/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.2142 - accuracy: 0.9827\n",
      "Epoch 139/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.2110 - accuracy: 0.9840\n",
      "Epoch 140/150\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.2078 - accuracy: 0.9827\n",
      "Epoch 141/150\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 0.2047 - accuracy: 0.9833\n",
      "Epoch 142/150\n",
      "1500/1500 [==============================] - 0s 250us/step - loss: 0.2019 - accuracy: 0.9827\n",
      "Epoch 143/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.1990 - accuracy: 0.9820\n",
      "Epoch 144/150\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.1962 - accuracy: 0.9800\n",
      "Epoch 145/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.1934 - accuracy: 0.9793\n",
      "Epoch 146/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.1908 - accuracy: 0.9813\n",
      "Epoch 147/150\n",
      "1500/1500 [==============================] - 0s 198us/step - loss: 0.1881 - accuracy: 0.9820\n",
      "Epoch 148/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.1857 - accuracy: 0.9820\n",
      "Epoch 149/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.1833 - accuracy: 0.9827\n",
      "Epoch 150/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.1809 - accuracy: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a5475ef98>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apprentissage modelmc \n",
    "\n",
    "modelmc.fit(XTrain, yTrain, epochs=150, batch_size=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 31us/step\n",
      "[0.1756314127445221, 0.9900000095367432]\n"
     ]
    }
   ],
   "source": [
    "#taux de succés \n",
    "score = modelmc.evaluate(XTest,yTest) \n",
    "\n",
    "print(score)   #0.99 ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
