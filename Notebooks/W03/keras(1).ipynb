{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras est une librairie Python qui permet d'avoir accès aux fonctions proposées par plusieurs librairies de machine learning (comme TensorFlow). Elle permet de simplifier la vie des neophytes de python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Perceptron simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation ici d'un jeu de données simple: probleme de discrimination binaire dans le plan. Les frontieres prenent la forme d'une parabole  \n",
    "                   Si (0.1 * X2 > X1²)  Alors (Y = positif) Sinon (Y = négatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement du dossier + importation des données\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:\\\\Users\\\\Utilisateur\\\\Downloads\")\n",
    "D = pd.read_table(\"artificial2d_data2.txt\",sep=\"\\t\",header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 3 columns):\n",
      "X1    2000 non-null float64\n",
      "X2    2000 non-null float64\n",
      "Y     2000 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(D.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    1141\n",
      "pos     859\n",
      "Name: Y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.value_counts(D.Y))   #regarde les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.zeros(D.shape[0])\n",
    "y[D.Y=='pos'] = 1  #ici positif = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))    #859 observation \"positives\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subdvision en échantillons d'apprentissage (1500 observations) et de test (500 observations)\n",
    "! il doit y avoir la même proportions d'observations positives (1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         X1     X2\n",
      "0    -0.355  0.676\n",
      "1     0.464  0.681\n",
      "2     0.001  0.294\n",
      "3     0.427  0.592\n",
      "4    -0.391  0.823\n",
      "...     ...    ...\n",
      "1995  0.194  0.539\n",
      "1996  0.061  0.998\n",
      "1997  0.083  0.156\n",
      "1998  0.184  0.556\n",
      "1999 -0.309  0.827\n",
      "\n",
      "[2000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "X = D.iloc[:,:2]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42933333333333334 0.43\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "#subdivision en 500 observations pour le test\n",
    "XTrain,XTest,yTrain,yTest = model_selection.train_test_split(X,y,test_size=500,random_state=1,stratify=y)\n",
    "\n",
    "print(np.mean(yTrain),np.mean(yTest))    #on observe la même proportions d'observations positives\n",
    "                                         #on peut commencer le processus d'apprentissage supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential, strucute vide qui permet de définir un empilement de couches de neurones\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential = ajoute des couches de façon sequentielle\n",
    "modelSimple = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture perception simple\n",
    "modelSimple.add(Dense(units=1,input_dim=2,activation=\"sigmoid\"))\n",
    "#on ajoute une couche qui relie directement la couche d'entrée #input_dim, nbr de neurones = nbr variables predictives\n",
    "# avec la couche de sortir #units = 1, 1 sortie ici la variable est binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](/Utilisateur/images/perceptron.jpg \"perceptron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithme d'apprentissage \n",
    "modelSimple.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=['accuracy'])\n",
    "#adam, algorithme d'optimisation\n",
    "#accuracy, taux de succès\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.6386 - accuracy: 0.6340\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6386 - accuracy: 0.6333\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6387 - accuracy: 0.6333\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6385 - accuracy: 0.6320\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6385 - accuracy: 0.6380\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.6384 - accuracy: 0.6340\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6384 - accuracy: 0.6353\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6384 - accuracy: 0.6340\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 0s 243us/step - loss: 0.6383 - accuracy: 0.6333\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.6383 - accuracy: 0.6307\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.6383 - accuracy: 0.6333\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6382 - accuracy: 0.6353\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6381 - accuracy: 0.6360\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6381 - accuracy: 0.6353\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 0.6381 - accuracy: 0.6347\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 0s 183us/step - loss: 0.6380 - accuracy: 0.6320\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6380 - accuracy: 0.6347\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 0s 248us/step - loss: 0.6379 - accuracy: 0.6340\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6379 - accuracy: 0.6340\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 0.6380 - accuracy: 0.6353\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.6379 - accuracy: 0.6333\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.6378 - accuracy: 0.6373\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 0s 185us/step - loss: 0.6378 - accuracy: 0.6313\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 0s 184us/step - loss: 0.6378 - accuracy: 0.6347\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6378 - accuracy: 0.6353\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.6377 - accuracy: 0.6327\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6378 - accuracy: 0.6360\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6377 - accuracy: 0.6333\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 0s 180us/step - loss: 0.6376 - accuracy: 0.6327\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6376 - accuracy: 0.6340\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.6377 - accuracy: 0.6333\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6376 - accuracy: 0.6347\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6376 - accuracy: 0.6373\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 0s 172us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 0s 234us/step - loss: 0.6375 - accuracy: 0.6347\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.6376 - accuracy: 0.6333\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.6376 - accuracy: 0.6360\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 0s 193us/step - loss: 0.6375 - accuracy: 0.6327\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 0s 227us/step - loss: 0.6375 - accuracy: 0.6340\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 0.6375 - accuracy: 0.6333\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6374 - accuracy: 0.6340\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.6374 - accuracy: 0.6327\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 0s 194us/step - loss: 0.6374 - accuracy: 0.6333\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 0s 202us/step - loss: 0.6374 - accuracy: 0.6373\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 0s 195us/step - loss: 0.6373 - accuracy: 0.6327\n",
      "Epoch 47/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.6374 - accuracy: 0.6367\n",
      "Epoch 48/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.6373 - accuracy: 0.6353\n",
      "Epoch 49/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.6374 - accuracy: 0.6340\n",
      "Epoch 50/150\n",
      "1500/1500 [==============================] - 0s 179us/step - loss: 0.6373 - accuracy: 0.6360\n",
      "Epoch 51/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6373 - accuracy: 0.6360\n",
      "Epoch 52/150\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.6373 - accuracy: 0.6360\n",
      "Epoch 53/150\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.6374 - accuracy: 0.6353\n",
      "Epoch 54/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6373 - accuracy: 0.6367\n",
      "Epoch 55/150\n",
      "1500/1500 [==============================] - 0s 222us/step - loss: 0.6372 - accuracy: 0.6367\n",
      "Epoch 56/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6372 - accuracy: 0.6367\n",
      "Epoch 57/150\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.6372 - accuracy: 0.6353\n",
      "Epoch 58/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6373 - accuracy: 0.6353\n",
      "Epoch 59/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6373 - accuracy: 0.6400\n",
      "Epoch 60/150\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.6371 - accuracy: 0.6360\n",
      "Epoch 61/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6372 - accuracy: 0.6367\n",
      "Epoch 62/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6372 - accuracy: 0.6367\n",
      "Epoch 63/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6371 - accuracy: 0.6360\n",
      "Epoch 64/150\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 0.6371 - accuracy: 0.6367\n",
      "Epoch 65/150\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.6371 - accuracy: 0.6360\n",
      "Epoch 66/150\n",
      "1500/1500 [==============================] - 0s 187us/step - loss: 0.6371 - accuracy: 0.6353\n",
      "Epoch 67/150\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6371 - accuracy: 0.6360\n",
      "Epoch 68/150\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6371 - accuracy: 0.6367\n",
      "Epoch 69/150\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.6371 - accuracy: 0.6393\n",
      "Epoch 70/150\n",
      "1500/1500 [==============================] - 0s 200us/step - loss: 0.6371 - accuracy: 0.6367\n",
      "Epoch 71/150\n",
      "1500/1500 [==============================] - 0s 207us/step - loss: 0.6371 - accuracy: 0.6360\n",
      "Epoch 72/150\n",
      "1500/1500 [==============================] - 0s 190us/step - loss: 0.6371 - accuracy: 0.6400\n",
      "Epoch 73/150\n",
      "1500/1500 [==============================] - 0s 192us/step - loss: 0.6371 - accuracy: 0.6347\n",
      "Epoch 74/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6371 - accuracy: 0.6387\n",
      "Epoch 75/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6370 - accuracy: 0.6407\n",
      "Epoch 76/150\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.6370 - accuracy: 0.6347\n",
      "Epoch 77/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6370 - accuracy: 0.6360\n",
      "Epoch 78/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6370 - accuracy: 0.6367\n",
      "Epoch 79/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.6370 - accuracy: 0.6380\n",
      "Epoch 80/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6370 - accuracy: 0.6360\n",
      "Epoch 81/150\n",
      "1500/1500 [==============================] - 0s 197us/step - loss: 0.6370 - accuracy: 0.6360\n",
      "Epoch 82/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6370 - accuracy: 0.6387\n",
      "Epoch 83/150\n",
      "1500/1500 [==============================] - 0s 213us/step - loss: 0.6370 - accuracy: 0.6347\n",
      "Epoch 84/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6369 - accuracy: 0.6360\n",
      "Epoch 85/150\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.6370 - accuracy: 0.6380\n",
      "Epoch 86/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6370 - accuracy: 0.6387\n",
      "Epoch 87/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6370 - accuracy: 0.6387\n",
      "Epoch 88/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6370 - accuracy: 0.6353\n",
      "Epoch 89/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6369 - accuracy: 0.6360\n",
      "Epoch 90/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.6369 - accuracy: 0.6380\n",
      "Epoch 91/150\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 0.6369 - accuracy: 0.6367\n",
      "Epoch 92/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6369 - accuracy: 0.6380\n",
      "Epoch 93/150\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 94/150\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.6369 - accuracy: 0.6420\n",
      "Epoch 95/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6369 - accuracy: 0.6387\n",
      "Epoch 96/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6369 - accuracy: 0.6380\n",
      "Epoch 97/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 98/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 99/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6369 - accuracy: 0.6367\n",
      "Epoch 100/150\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.6368 - accuracy: 0.6367\n",
      "Epoch 101/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6369 - accuracy: 0.6393\n",
      "Epoch 102/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6369 - accuracy: 0.6367\n",
      "Epoch 103/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6367\n",
      "Epoch 104/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6373\n",
      "Epoch 105/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 106/150\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 107/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6368 - accuracy: 0.6407\n",
      "Epoch 108/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6368 - accuracy: 0.6353\n",
      "Epoch 109/150\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.6368 - accuracy: 0.6367\n",
      "Epoch 110/150\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.6369 - accuracy: 0.6380\n",
      "Epoch 111/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 112/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6393\n",
      "Epoch 113/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6368 - accuracy: 0.6373\n",
      "Epoch 114/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6367 - accuracy: 0.6367\n",
      "Epoch 115/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6367 - accuracy: 0.6380\n",
      "Epoch 116/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6367 - accuracy: 0.6380\n",
      "Epoch 117/150\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 0.6367 - accuracy: 0.6393\n",
      "Epoch 118/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6367 - accuracy: 0.6387\n",
      "Epoch 119/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6367 - accuracy: 0.6387\n",
      "Epoch 120/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6367 - accuracy: 0.6380\n",
      "Epoch 121/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6380\n",
      "Epoch 122/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6367 - accuracy: 0.6373\n",
      "Epoch 123/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 124/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 125/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 126/150\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.6366 - accuracy: 0.6387\n",
      "Epoch 127/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6367 - accuracy: 0.6393\n",
      "Epoch 128/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6367 - accuracy: 0.6413\n",
      "Epoch 129/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6368 - accuracy: 0.6387\n",
      "Epoch 130/150\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.6366 - accuracy: 0.6380\n",
      "Epoch 131/150\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.6366 - accuracy: 0.6380\n",
      "Epoch 132/150\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 133/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6366 - accuracy: 0.6387\n",
      "Epoch 134/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6367 - accuracy: 0.6387\n",
      "Epoch 135/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6366 - accuracy: 0.6387\n",
      "Epoch 136/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6367 - accuracy: 0.6387\n",
      "Epoch 137/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6366 - accuracy: 0.6400\n",
      "Epoch 138/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6366 - accuracy: 0.6380\n",
      "Epoch 139/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6366 - accuracy: 0.6393\n",
      "Epoch 140/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6366 - accuracy: 0.6387\n",
      "Epoch 141/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 142/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.6367 - accuracy: 0.6387\n",
      "Epoch 143/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.6366 - accuracy: 0.6387\n",
      "Epoch 144/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6366 - accuracy: 0.6373\n",
      "Epoch 145/150\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.6365 - accuracy: 0.6373\n",
      "Epoch 146/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6365 - accuracy: 0.6367\n",
      "Epoch 147/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6365 - accuracy: 0.6387\n",
      "Epoch 148/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6365 - accuracy: 0.6393\n",
      "Epoch 149/150\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.6365 - accuracy: 0.6367\n",
      "Epoch 150/150\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.6365 - accuracy: 0.6380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f7a95762b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apprentissage\n",
    "modelSimple.fit(XTrain,yTrain,epochs=150,batch_size=10)\n",
    "#epochs : nbr max d'iterations\n",
    "#batch_size : nbr d'observations avec de remettre a jour poids synaptiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.5999742],\n",
      "       [5.2529926]], dtype=float32), array([-1.6678811], dtype=float32), array([[2.3024518]], dtype=float32), array([-1.8396214], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(modelSimple.get_weights())\n",
    "#Petite matrice 2x1\n",
    "#poids de 2 neurones d'entrées + biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#echantillon test\n",
    "predic=modelSimple.predict_classes(XTest)\n",
    "print(predic[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.622\n"
     ]
    }
   ],
   "source": [
    "#taux de succès\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(yTest,predic))\n",
    "\n",
    "#0.62 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
